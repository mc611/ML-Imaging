{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already downloaded train-images-idx3-ubyte.gz\n",
      "Already downloaded train-labels-idx1-ubyte.gz\n",
      "Already downloaded t10k-images-idx3-ubyte.gz\n",
      "Already downloaded t10k-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/mnist-data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/mnist-data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/mnist-data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/mnist-data/t10k-labels-idx1-ubyte.gz\n",
      "Validation shape (5000, 28, 28, 1)\n",
      "Train size 55000\n"
     ]
    }
   ],
   "source": [
    "# Function to get data\n",
    "\n",
    "import os\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "import gzip, binascii, struct, numpy\n",
    "\n",
    "SOURCE_URL = 'https://storage.googleapis.com/cvdf-datasets/mnist/'\n",
    "WORK_DIRECTORY = \"/tmp/mnist-data\"\n",
    "IMAGE_SIZE = 28\n",
    "PIXEL_DEPTH = 255\n",
    "VALIDATION_SIZE = 5000\n",
    "NUM_LABELS = 10\n",
    "\n",
    "def maybe_download(filename):\n",
    "    \"\"\"A helper to download the data files if not present.\"\"\"\n",
    "    if not os.path.exists(WORK_DIRECTORY):\n",
    "        os.mkdir(WORK_DIRECTORY)\n",
    "    filepath = os.path.join(WORK_DIRECTORY, filename)\n",
    "    if not os.path.exists(filepath):\n",
    "        filepath, _ = urlretrieve(SOURCE_URL + filename, filepath)\n",
    "        statinfo = os.stat(filepath)\n",
    "        print('Successfully downloaded', filename, statinfo.st_size, 'bytes.')\n",
    "    else:\n",
    "        print('Already downloaded', filename)\n",
    "    return filepath\n",
    "\n",
    "def extract_data(filename, num_images):\n",
    "    \"\"\"Extract the images into a 4D tensor [image index, y, x, channels].\n",
    "  \n",
    "    For MNIST data, the number of channels is always 1.\n",
    "\n",
    "    Values are rescaled from [0, 255] down to [-0.5, 0.5].\n",
    "    \"\"\"\n",
    "    print('Extracting', filename)\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        # Skip the magic number and dimensions; we know these values.\n",
    "        bytestream.read(16)\n",
    "\n",
    "        buf = bytestream.read(IMAGE_SIZE * IMAGE_SIZE * num_images)\n",
    "        data = numpy.frombuffer(buf, dtype=numpy.uint8).astype(numpy.float32)\n",
    "        data = (data - (PIXEL_DEPTH / 2.0)) / PIXEL_DEPTH\n",
    "        data = data.reshape(num_images, IMAGE_SIZE, IMAGE_SIZE, 1)\n",
    "        return data\n",
    "\n",
    "def extract_labels(filename, num_images):\n",
    "    \"\"\"Extract the labels into a 1-hot matrix [image index, label index].\"\"\"\n",
    "    print('Extracting', filename)\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        # Skip the magic number and count; we know these values.\n",
    "        bytestream.read(8)\n",
    "        buf = bytestream.read(1 * num_images)\n",
    "        labels = numpy.frombuffer(buf, dtype=numpy.uint8)\n",
    "    # Convert to dense 1-hot representation.\n",
    "    return (numpy.arange(NUM_LABELS) == labels[:, None]).astype(numpy.float32)\n",
    "\n",
    "def get_data():\n",
    "    train_data_filename = maybe_download('train-images-idx3-ubyte.gz')\n",
    "    train_labels_filename = maybe_download('train-labels-idx1-ubyte.gz')\n",
    "    test_data_filename = maybe_download('t10k-images-idx3-ubyte.gz')\n",
    "    test_labels_filename = maybe_download('t10k-labels-idx1-ubyte.gz')\n",
    "\n",
    "    train_data = extract_data(train_data_filename, 60000)\n",
    "    test_data = extract_data(test_data_filename, 10000)\n",
    "    train_labels = extract_labels(train_labels_filename, 60000)\n",
    "    test_labels = extract_labels(test_labels_filename, 10000)\n",
    "\n",
    "    validation_data = train_data[:VALIDATION_SIZE, :, :, :]\n",
    "    validation_labels = train_labels[:VALIDATION_SIZE]\n",
    "    train_data = train_data[VALIDATION_SIZE:, :, :, :]\n",
    "    train_labels = train_labels[VALIDATION_SIZE:]\n",
    "    train_size = train_labels.shape[0]\n",
    "    print('Validation shape', validation_data.shape)\n",
    "    print('Train size', train_size)\n",
    "    \n",
    "    return train_data, train_labels, validation_data, validation_labels\n",
    "X_train, y_train, X_val, y_val = mnist_data.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape (55000, 28, 28, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print('Training data shape', X_train.shape)\n",
    "_, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(X_train[0].reshape(28, 28), cmap=plt.cm.Greys);\n",
    "ax2.imshow(X_train[1].reshape(28, 28), cmap=plt.cm.Greys);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "features_placeholder = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "labels_placeholder = tf.placeholder(tf.float32, [None, 10])\n",
    "batch_size_placeholder = tf.placeholder(tf.int64, [])\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((features_placeholder, labels_placeholder))\n",
    "dataset = dataset.batch(batch_size_placeholder)\n",
    "dataset = dataset.repeat(100)\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "x_batch, y_batch = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Weights Init\n",
    "conv1_weights = tf.get_variable(\"conv1\", shape=[5, 5, 1, 32], initializer=tf.contrib.layers.xavier_initializer())\n",
    "conv1_biases  = tf.get_variable(\"conv1_bias\", shape=[32], initializer=tf.zeros_initializer())\n",
    "\n",
    "conv2_weights = tf.get_variable(\"conv2\", shape=[5, 5, 32, 64], initializer=tf.contrib.layers.xavier_initializer())\n",
    "conv2_biases  = tf.get_variable(\"conv2_bias\", shape=[64], initializer=tf.zeros_initializer())\n",
    "\n",
    "fc1_weights = tf.get_variable(\"fc1\", shape=[7*7*64, 512], initializer=tf.contrib.layers.xavier_initializer())\n",
    "fc1_biases = tf.get_variable(\"fc1_bias\", shape=[512], initializer=tf.zeros_initializer())\n",
    "\n",
    "fc2_weights = tf.get_variable(\"fc2\", shape=[512, 10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "fc2_biases = tf.get_variable(\"fc2_bias\", shape=[10], initializer=tf.zeros_initializer())\n",
    "\n",
    "def model(data):\n",
    "    \"\"\"The Model definition.\"\"\"\n",
    "    conv = tf.nn.conv2d(data, conv1_weights, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    relu = tf.nn.relu(tf.nn.bias_add(conv, conv1_biases))\n",
    "    pool = tf.nn.max_pool(relu, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "    conv = tf.nn.conv2d(pool, conv2_weights, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    relu = tf.nn.relu(tf.nn.bias_add(conv, conv2_biases))\n",
    "    pool = tf.nn.max_pool(relu, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    pool_shape = pool.get_shape().as_list()\n",
    "    reshape = tf.reshape(pool, [-1, pool_shape[1] * pool_shape[2] * pool_shape[3]])\n",
    "    hidden = tf.nn.relu(tf.matmul(reshape, fc1_weights) + fc1_biases)\n",
    "\n",
    "    return tf.matmul(hidden, fc2_weights) + fc2_biases\n",
    "\n",
    "print('Done')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = tf.Variable(0)\n",
    "logits = model(x_batch)\n",
    "prediction = tf.nn.softmax(logits)\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_batch, logits=logits))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 1e-1)\n",
    "train_op = optimizer.minimize(loss, global_step=counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "tf.global_variables_initializer().run(session=sess)\n",
    "sess.run(iterator.initializer, feed_dict={features_placeholder: X_train, labels_placeholder: y_train, batch_size_placeholder: 64})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  2.3070822\n",
      "loss:  0.1530393\n",
      "loss:  0.0068216682\n",
      "loss:  0.0033742092\n",
      "loss:  0.011832637\n"
     ]
    }
   ],
   "source": [
    "steps = y_train.shape[0]*5 // 64\n",
    "for step in range(steps):\n",
    "    _, l = sess.run([train_op, loss])\n",
    "    if step % 1000 == 0:\n",
    "        print('loss: ', l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(iterator.initializer, feed_dict={features_placeholder: X_val, labels_placeholder: y_val, batch_size_placeholder: y_val.shape[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_pred, np_loss, np_labels = sess.run([prediction, loss, y_batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[478,   0,   0,   0,   0,   0,   2,   0,   0,   1],\n",
       "       [  0, 561,   1,   0,   0,   1,   2,   2,   1,   1],\n",
       "       [  1,   0, 486,   5,   0,   1,   2,   3,   8,   1],\n",
       "       [  0,   0,   0, 484,   0,   1,   0,   0,   1,   0],\n",
       "       [  0,   0,   0,   0, 533,   0,   0,   1,   1,   1],\n",
       "       [  0,   0,   0,   0,   0, 429,   0,   1,   1,   0],\n",
       "       [  0,   0,   0,   0,   0,   0, 495,   0,   1,   1],\n",
       "       [  0,   2,   0,   3,   1,   0,   0, 543,   0,   5],\n",
       "       [  0,   0,   0,   0,   0,   1,   0,   0, 448,   1],\n",
       "       [  0,   0,   1,   1,   1,   1,   0,   0,   1, 484]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "confusion_matrix(np.argmax(np_pred, axis=1), np.argmax(np_labels, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape (55000, 28, 28, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# View images that we failed to classify out of interest\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print('Training data shape', X_train.shape)\n",
    "_, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(X_val[~(np.argmax(np_pred, axis=1)==np.argmax(np_labels, axis=1))][32].reshape(28, 28), cmap=plt.cm.Greys);\n",
    "ax2.imshow(X_val[~(np.argmax(np_pred, axis=1)==np.argmax(np_labels, axis=1))][30].reshape(28, 28), cmap=plt.cm.Greys);\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
