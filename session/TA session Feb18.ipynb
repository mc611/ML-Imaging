{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train,y_train),(X_test,y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast from float64 to float32\n",
    "\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "\n",
    "# add channels dimension\n",
    "X_train = X_train[...,None]\n",
    "X_test = X_test[..., None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(60000,)\n",
      "(10000, 28, 28, 1)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "symbolically generate a batch of images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tarin_or_test = tf.placeholder(tf.float32, shape=[None,28,28,1], name='input_image')\n",
    "y_train_or_test = tf.placeholder(tf.int32, shape=[None],name='image_label' )\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X_tarin_or_test,y_train_or_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.batch(batch_size)\n",
    "batch_generator = dataset.make_initializable_iterator()\n",
    "X_batch, y_batch = batch_generator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'IteratorGetNext_1:1' shape=(?,) dtype=int32>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "given a symbolic batch, symbolically process it through a network and output the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = X_batch\n",
    "\n",
    "# add conv layers\n",
    "\n",
    "layer1 = tf.layers.conv2d(net,filters=32,kernel_size=3,padding='SAME',activation=tf.nn.relu)\n",
    "layer2 = tf.layers.conv2d(layer1,filters=32,kernel_size=3,padding='SAME',activation=tf.nn.relu)\n",
    "layer3 = tf.layers.max_pooling2d(layer2,pool_size=2,strides=2)\n",
    "\n",
    "layer4 = tf.layers.conv2d(layer3,filters=32,kernel_size=3,padding='SAME',activation=tf.nn.relu)\n",
    "layer5 = tf.layers.conv2d(layer4,filters=32,kernel_size=3,padding='SAME',activation=tf.nn.relu)\n",
    "layer6 = tf.layers.max_pooling2d(layer5,pool_size=2,strides=2)\n",
    "\n",
    "# fully connected layer:\n",
    "fc = tf.layers.flatten(layer6)\n",
    "fc = tf.layers.dense(fc,units=512,activation=tf.nn.relu)\n",
    "logits = tf.layers.dense(fc,units=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.softmax_cross_entropy(onehot_labels=tf.one_hot(y_batch,depth=10),logits=logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "given a loss, create op that, when run, descends the gradient by one step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_op = tf.train.GradientDescentOptimizer(learning_rate=.001).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "start a tensorflow session and use it to initialize all variables and ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(device_count={'GPU':0})\n",
    "sess = tf.InterativeSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "do gradient descent: run a train loop over multiple iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    " sess.run(batch_generator.initializer,feed_dict{X_train_or_test: X_train, y_train_or_test: y_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    _, loss_i = sess.run([train_op,loss])\n",
    "    if i%100 == 0:\n",
    "        print(loss_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pass through the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(batch_generator.initializer, feed_dict{X_train_or_test:X_test, y_train_or_test:y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for i in range(100):\n",
    "    prediction, truth = sess.run([logits,y_batch])\n",
    "    correct += np.sum(prediction.argmax(1)==truth)\n",
    "    total +=len(truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(correct/total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
